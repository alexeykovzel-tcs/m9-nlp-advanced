{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1f39de4",
   "metadata": {},
   "source": [
    "# Regular Part\n",
    "The first section of the regular-level exercises, we will explore how to use our saved model to make predictions on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0dc5ab93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T22:01:46.981768141Z",
     "start_time": "2023-10-22T22:01:46.936921780Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326623fa",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Refer to Keras again on how to load your saved model, [here](https://www.tensorflow.org/guide/keras/save_and_serialize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6154cbd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T22:30:55.966892414Z",
     "start_time": "2023-10-22T22:30:55.871529460Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('tagger-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef914510",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T22:01:49.702103715Z",
     "start_time": "2023-10-22T22:01:49.684782206Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'The articles in this special section focus on using natural language generation techniques (NLG) and natural language processing (NLP) to build computational systems that generate reports and other kinds of text in human languages.',\n",
    "    'NLG uses analytics, AI, and NLP to obtain relevant information about non-linguistic data and to generate textual summaries and explanations of these data which help people understand and benefit from them.',\n",
    "    'In this regard, NLG is a research field that addresses the data-value chain by using natural language as a tool for bridging the gap between raw data and valuable information communicated to users in a comprehensible way, adapted to their information needs.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb18c2a",
   "metadata": {},
   "source": [
    "a. We want to be able to tag the three sentences in the corpus above [source](https://ieeexplore.ieee.org/document/7983468).\n",
    "\n",
    "Figure out the necessary steps that should precede passing the input into your **h5** model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29db65b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-22T22:01:52.489463445Z",
     "start_time": "2023-10-22T22:01:52.452308514Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 271\n",
    "\n",
    "with open('tagger-tokenizer.pkl', 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "corpus_encoded = tokenizer.texts_to_sequences(corpus)\n",
    "corpus_padded = pad_sequences(corpus_encoded, maxlen=max_len, padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc4d74",
   "metadata": {},
   "source": [
    "b. Use the model to make the predictions on this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[[9.14407551e-01, 1.98224038e-02, 4.11222689e-03, ...,\n         3.30577535e-03, 1.72776345e-04, 1.85140863e-03],\n        [9.91388500e-01, 1.57263805e-03, 2.42202150e-04, ...,\n         3.61038168e-04, 1.05591180e-05, 1.68475599e-04],\n        [9.96884167e-01, 4.93137981e-04, 6.65069310e-05, ...,\n         1.30541259e-04, 2.94757751e-06, 5.61589113e-05],\n        ...,\n        [3.72465365e-02, 2.85448611e-01, 1.15548983e-01, ...,\n         2.32355669e-02, 4.46862401e-03, 1.95980594e-02],\n        [3.72465365e-02, 2.85448611e-01, 1.15548983e-01, ...,\n         2.32355669e-02, 4.46862401e-03, 1.95980594e-02],\n        [3.72465365e-02, 2.85448611e-01, 1.15548983e-01, ...,\n         2.32355669e-02, 4.46862401e-03, 1.95980594e-02]],\n\n       [[9.14407551e-01, 1.98224038e-02, 4.11222689e-03, ...,\n         3.30577535e-03, 1.72776345e-04, 1.85140863e-03],\n        [9.91388500e-01, 1.57263805e-03, 2.42202150e-04, ...,\n         3.61038168e-04, 1.05591180e-05, 1.68475599e-04],\n        [9.96884167e-01, 4.93137981e-04, 6.65069310e-05, ...,\n         1.30541259e-04, 2.94757751e-06, 5.61589113e-05],\n        ...,\n        [3.72465365e-02, 2.85448611e-01, 1.15548983e-01, ...,\n         2.32355669e-02, 4.46862401e-03, 1.95980594e-02],\n        [3.72465365e-02, 2.85448611e-01, 1.15548983e-01, ...,\n         2.32355669e-02, 4.46862401e-03, 1.95980594e-02],\n        [3.72465365e-02, 2.85448611e-01, 1.15548983e-01, ...,\n         2.32355669e-02, 4.46862401e-03, 1.95980594e-02]],\n\n       [[9.14407551e-01, 1.98224038e-02, 4.11222689e-03, ...,\n         3.30577535e-03, 1.72776345e-04, 1.85140863e-03],\n        [9.91388500e-01, 1.57263805e-03, 2.42202150e-04, ...,\n         3.61038168e-04, 1.05591180e-05, 1.68475599e-04],\n        [9.96884167e-01, 4.93137981e-04, 6.65069310e-05, ...,\n         1.30541259e-04, 2.94757751e-06, 5.61589113e-05],\n        ...,\n        [3.72465327e-02, 2.85448581e-01, 1.15548976e-01, ...,\n         2.32355651e-02, 4.46862355e-03, 1.95980575e-02],\n        [3.72465327e-02, 2.85448581e-01, 1.15548976e-01, ...,\n         2.32355651e-02, 4.46862355e-03, 1.95980575e-02],\n        [3.72465327e-02, 2.85448581e-01, 1.15548976e-01, ...,\n         2.32355651e-02, 4.46862355e-03, 1.95980575e-02]]], dtype=float32)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.predict(corpus_padded)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T22:02:01.538934039Z",
     "start_time": "2023-10-22T22:02:01.476133362Z"
    }
   },
   "id": "9175c0d8c015c1df"
  },
  {
   "cell_type": "markdown",
   "id": "b56e7cab",
   "metadata": {},
   "source": [
    "c. Tag the corpus above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "tagged_corpus = []\n",
    "for word_indexes, tag_probs in zip(corpus_encoded, output):\n",
    "    words = [tokenizer.index_word[idx] for idx in word_indexes]\n",
    "    tags = [tokenizer.index_word[np.argmax(p) + 1] for p in tag_probs]\n",
    "    tags = tags[max(0, max_len-len(words)):]\n",
    "    tagged_corpus.append([words, tags])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T22:29:44.968551830Z",
     "start_time": "2023-10-22T22:29:44.924829256Z"
    }
   },
   "id": "159fe1edeb55d479"
  },
  {
   "cell_type": "markdown",
   "id": "015b9166",
   "metadata": {},
   "source": [
    "d. Save the corpus and the predictions on a file, and upload it with your submission on Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tagged_corpus, columns=['words', 'tags'])\n",
    "df.to_csv('tagged-corpus.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-22T22:29:47.524436774Z",
     "start_time": "2023-10-22T22:29:47.521430031Z"
    }
   },
   "id": "dddfab6dfd0e43b2"
  },
  {
   "cell_type": "markdown",
   "id": "fbeb26ab",
   "metadata": {},
   "source": [
    "## Advanced part\n",
    "\n",
    "Use a scraping library, [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) should work, but feel free to choose anything you wish.\n",
    "\n",
    "Scrape some publicly available text (public speeches, lyrics, poetry..etc), and build a corpus of your own.\n",
    "\n",
    "Use a one-to-many RNN (any RNN you want, vanilla, LSTM, GRU or a biderectional version, etc.) to perform some natural language generation resembling the corpus your model was trained on.\n",
    "\n",
    "You don't have to train the model for hours, just show that your model works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac3958de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
